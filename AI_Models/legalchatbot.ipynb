{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers torch accelerate\n!pip install bitsandbytes accelerate transformers torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"AISimplyExplained/Vakil-7B\", device_map=\"auto\")\n\n# Generate text\nprompt = \"The future of AI in law is\"\noutput = pipe(prompt, max_length=100, do_sample=True, temperature=0.7)\n\nprint(output[0]['generated_text'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate text\nprompt = \"What is the procedure of registering FIR in India\"\noutput = pipe(prompt, max_length=512, do_sample=True, temperature=0.7)\n\nprint(output[0]['generated_text'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install pyngrok\n!ngrok config add-authtoken 2tM3DYgLA5nFdgtHTAeERq6sLJC_2Vsp1uCzyVVJc7qQLSNid\n!pip install cors\n!pip install flask-cors\nimport os\nfrom flask import Flask, request, jsonify\nfrom flask_cors import CORS\nfrom transformers import pipeline\nfrom pyngrok import ngrok\n\n# Initialize Flask app and enable CORS\napp = Flask(__name__)\nCORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n\n# Load your text-generation pipeline with the Vakil-7B model\nchatbot_pipe = pipeline(\n    \"text-generation\",\n    model=\"AISimplyExplained/Vakil-7B\",\n    device_map=\"auto\"\n)\n\n@app.route('/chat', methods=['POST'])\ndef chat():\n    data = request.get_json()\n    if not data or \"prompt\" not in data:\n        return jsonify({\"error\": \"Please provide a prompt in the JSON payload\"}), 400\n\n    prompt = data[\"prompt\"]\n    \n    # Generate a response using the pipeline.\n    # Adjust parameters as needed (e.g., max_length, temperature)\n    responses = chatbot_pipe(prompt, max_length=100, do_sample=True, temperature=0.7)\n    \n    # The pipeline returns a list of dicts; we'll extract the first generated text.\n    generated_text = responses[0][\"generated_text\"]\n\n    return jsonify({\"response\": generated_text})\n\nif __name__ == '__main__':\n    public_url = ngrok.connect(5000).public_url\n    print(\"Public URL:\", public_url)\n    app.run(host=\"0.0.0.0\", port=5000)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T07:53:04.732657Z","iopub.execute_input":"2025-02-22T07:53:04.733089Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.3)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\nAuthtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\nRequirement already satisfied: cors in /usr/local/lib/python3.10/dist-packages (1.0.1)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from cors) (0.4.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from cors) (2.32.3)\nCollecting argparse (from cors)\n  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: gevent in /usr/local/lib/python3.10/dist-packages (from cors) (24.11.1)\nRequirement already satisfied: tldextract in /usr/local/lib/python3.10/dist-packages (from cors) (5.1.3)\nRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from cors) (1.0.0)\nRequirement already satisfied: PySocks in /usr/local/lib/python3.10/dist-packages (from cors) (1.7.1)\nRequirement already satisfied: zope.event in /usr/local/lib/python3.10/dist-packages (from gevent->cors) (5.0)\nRequirement already satisfied: zope.interface in /usr/local/lib/python3.10/dist-packages (from gevent->cors) (7.2)\nRequirement already satisfied: greenlet>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from gevent->cors) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->cors) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->cors) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->cors) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->cors) (2025.1.31)\nRequirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract->cors) (2.1.0)\nRequirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->cors) (3.17.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.event->gevent->cors) (75.1.0)\nUsing cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\nInstalling collected packages: argparse\nSuccessfully installed argparse-1.4.0\nRequirement already satisfied: flask-cors in /usr/local/lib/python3.10/dist-packages (5.0.0)\nRequirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask-cors) (3.1.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (8.1.7)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (1.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-cors) (3.0.2)\n","output_type":"stream"},{"name":"stderr","text":"Unused kwargs: ['quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Public URL: https://0104-35-247-86-88.ngrok-free.app\n * Serving Flask app '__main__'\n * Debug mode: off\n","output_type":"stream"},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}