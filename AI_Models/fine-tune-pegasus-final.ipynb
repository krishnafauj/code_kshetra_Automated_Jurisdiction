{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7868867,"sourceType":"datasetVersion","datasetId":4616972}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction to Pegasus","metadata":{}},{"cell_type":"markdown","source":"# 1. Preprocessing data","metadata":{}},{"cell_type":"markdown","source":"PEGASUS (Pre-training with Extracted Gap-sentences for Abstractive Summarization) is a state-of-the-art language model developed by Google Research, designed specifically for abstractive text summarization tasks. Unlike traditional models, PEGASUS introduces a novel pretraining objective called Gap Sentence Generation (GSG), which closely aligns with the summarization process.\n\nDuring pretraining, PEGASUS is fine-tuned by masking entire sentences in a document and training the model to generate these missing sentences based on the surrounding context. This approach enables the model to focus on understanding the core ideas of a document, simulating the process of creating summaries. By leveraging GSG and massive-scale datasets, PEGASUS achieves remarkable performance on a variety of summarization benchmarks, such as CNN/DailyMail and XSum, often exceeding prior models in terms of coherence and informativeness.\n\nPEGASUS is built on the Transformer architecture and benefits from its scalability and parallelization, making it suitable for a wide range of natural language processing applications beyond summarization. Its implementation and pretrained weights are accessible through the [Hugging Face](https://huggingface.co/docs/transformers/en/model_doc/pegasus) Transformers library, enabling researchers and developers to explore its capabilities and adapt it for specific use cases with ease.\n\n*(Text henerated with the help from ChatGPT)*","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython import get_ipython\nget_ipython().cache_size = 0  # Disable output cache\n\n# Clean workspace\nimport gc\nimport torch\n\n# Clear unnecessary variables\ndef clean_workspace():\n    print(\"Cleaning workspace...\")\n    \n    # Delete all variables in the global scope except system modules\n    global_vars = list(globals().keys())\n    for var in global_vars:\n        if var not in [\"gc\", \"torch\", \"clean_workspace\"]:  # Keep required modules and function\n            del globals()[var]\n    \n    # Clear GPU memory\n    print(\"Clearing GPU memory...\")\n    torch.cuda.empty_cache()\n    torch.cuda.synchronize()\n\n    # Perform garbage collection\n    print(\"Running garbage collection...\")\n    gc.collect()\n\n    print(\"Workspace cleaned successfully!\")\n\n# Call the function\nclean_workspace()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.1 Import necessary libraries","metadata":{}},{"cell_type":"code","source":"%%capture captured_output\n!pip install sentence_transformers bert_score evaluate\n! pip install rouge_score\n\nimport pandas as pd \nimport shutil\nimport random\nfrom transformers import PegasusTokenizer, PegasusForConditionalGeneration, Trainer, TrainingArguments\nfrom datasets import Dataset\n\n# for evaluation\nimport os\nimport torch\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport evaluate\nfrom bert_score import score\nimport numpy as np\n\n# Load sentence transformer for embeddings\nsentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n\n# Load ROUGE metric\nrouge = evaluate.load(\"rouge\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2 Create datasets for train and test","metadata":{}},{"cell_type":"code","source":"# Function to load data from text files\ndef load_data(judgement_folder, summary_folder, max_files=6000):\n    data = []\n    # List files in judgement and summary folders\n    judgement_files = sorted(os.listdir(judgement_folder))[:max_files]\n    summary_files = sorted(os.listdir(summary_folder))[:max_files]\n\n    # Loop through first `max_files` files\n    for j_file, s_file in zip(judgement_files, summary_files):\n        with open(os.path.join(judgement_folder, j_file), 'r') as j_f:\n            judgement_text = j_f.read()\n        with open(os.path.join(summary_folder, s_file), 'r') as s_f:\n            summary_text = s_f.read()\n\n        # Append data to list\n        data.append({\"judgement\": judgement_text, \"summary\": summary_text})\n    \n    return data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load training and test data\ntest_data = load_data(\"/kaggle/input/legal-case-document-summarization/dataset/IN-Abs/test-data/judgement\", \"/kaggle/input/legal-case-document-summarization/dataset/IN-Abs/test-data/summary\")\ntrain_data = load_data(\"/kaggle/input/legal-case-document-summarization/dataset/IN-Abs/train-data/judgement\", \"/kaggle/input/legal-case-document-summarization/dataset/IN-Abs/train-data/summary\")\n\n# Convert to Hugging Face Dataset\ntrain_dataset = Dataset.from_list(train_data)\ntest_dataset = Dataset.from_list(test_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Train Pegasus Model","metadata":{}},{"cell_type":"code","source":"%%capture captured_output\n# Check if GPU is availablee\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Training on: {device}\")\n\n# Load in pre trained Pegasus Model\ntokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\nmodel = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\").to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.1 Generated summaries with Pre-trained model","metadata":{}},{"cell_type":"markdown","source":"To compare the performances between pre-trained Pegasus model and fine-tuned pegasus model, we generated summaries with pre-trained model first to calculate ROUGE scores and Bert score.","metadata":{}},{"cell_type":"code","source":"%%capture captured_output\n\ntest_dir = '/kaggle/input/legal-case-document-summarization/dataset/IN-Abs/test-data/judgement'\nsummary_dir = '/kaggle/input/legal-case-document-summarization/dataset/IN-Abs/test-data/summary'\n\npre_generated_summaries = []\nreference_summaries = []\npre_cosine_similarities = []\n\n# Loop through the test files\nfor filename in os.listdir(test_dir):\n    if filename.endswith('.txt'):\n        # Read the test document\n        with open(os.path.join(test_dir, filename), 'r', encoding='utf-8') as file:\n            test_document = file.read()\n            \n        # Read the corresponding reference summary\n        with open(os.path.join(summary_dir, filename), 'r', encoding='utf-8') as ref_file:\n            reference_summary = ref_file.read()\n            reference_summaries.append(reference_summary)\n\n        # Tokenize and generate summary using pre_trained Pegasus\n        inputs = tokenizer(test_document, return_tensors=\"pt\", max_length=1024, truncation=True)\n        input_ids = inputs[\"input_ids\"].to(device)  # Send input_ids tensor to the device\n        attention_mask = inputs[\"attention_mask\"].to(device)  # Send attention mask to the device\n\n        # Generate the summary\n        summary_ids = model.generate(input_ids, attention_mask=attention_mask, max_length=150, min_length=40, \n                                     length_penalty=2.0, num_beams=4, early_stopping=True)\n        pre_generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n        pre_generated_summaries.append(pre_generated_summary)\n\n        # Calculate cosine similarity using sentence embeddings\n        ref_embedding = sentence_model.encode([reference_summary])[0]\n        gen_embedding = sentence_model.encode([pre_generated_summary])[0]\n\n        cosine_sim = cosine_similarity([ref_embedding], [gen_embedding])\n        pre_cosine_similarities.append(cosine_sim[0][0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate average cosine similarity\npre_average_cosine_similarity = np.mean(pre_cosine_similarities)\nprint(f\"Average Cosine Similarity for Pre Trained Pegasus: {pre_average_cosine_similarity}\")\n\n# Calculate ROUGE score\nrouge_scores = rouge.compute(predictions=pre_generated_summaries, references=reference_summaries)\nprint(f\"ROUGE scores for Pre Trained Pegasus: {rouge_scores}\")\n\n# Calculate BERTScore\nP, R, F1 = score(pre_generated_summaries, reference_summaries, lang='en', rescale_with_baseline=True)\navg_f1 = np.mean(F1.numpy())\nprint(f\"BERTScore F1 for Pre Trained Pegasus: {avg_f1}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2 Fine tune the model","metadata":{}},{"cell_type":"code","source":"# Tokenization\ndef preprocess_function(examples):\n    model_inputs = tokenizer(examples[\"judgement\"], max_length=1024, truncation=True, padding=\"max_length\")\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(examples[\"summary\"], max_length=256, truncation=True, padding=\"max_length\")\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n# Tokenize the datasets\ntokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\ntokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We learned the training arguments from [this kaggle notebook](https://www.kaggle.com/code/sathwikareddy28/casemain).","metadata":{}},{"cell_type":"code","source":"# Define Training Arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy=\"epoch\",   # Evaluate every epoch\n    learning_rate=2e-5,\n    per_device_train_batch_size=1,  # Adjust batch size based on GPU memory\n    per_device_eval_batch_size=1,   # Adjust batch size based on GPU memory\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    save_total_limit=None,\n    save_steps=0,\n    report_to=\"none\",  # Disable reports to WandB, etc.\n    fp16=True,  # Enable mixed precision for faster training on GPU\n)\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_test_dataset,  # Evaluation on test dataset\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start Training\ntrainer.train()\n\n# Save the fine-tuned model\nmodel.save_pretrained('./fine_tuned_pegasus_model')\ntokenizer.save_pretrained('./fine_tuned_pegasus_model')\n\nprint(\"Training complete and model saved.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Evaluation","metadata":{}},{"cell_type":"code","source":"# Check if GPU is available and set the device for the model\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ntorch.cuda.empty_cache()\n\n# Load the Pegasus model and tokenizer for summary generation\nmodel = PegasusForConditionalGeneration.from_pretrained(\"/kaggle/working/fine_tuned_pegasus_model\").to(device)\ntokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture captured_output\n\ntest_dir = '/kaggle/input/legal-case-document-summarization/dataset/IN-Abs/test-data/judgement'\nsummary_dir = '/kaggle/input/legal-case-document-summarization/dataset/IN-Abs/test-data/summary'\n\ngenerated_summaries = []\nreference_summaries = []\ncosine_similarities = []\n\n# Loop through the test files\nfor filename in os.listdir(test_dir):\n    if filename.endswith('.txt'):\n        # Read the test document\n        with open(os.path.join(test_dir, filename), 'r', encoding='utf-8') as file:\n            test_document = file.read()\n            \n        # Read the corresponding reference summary\n        with open(os.path.join(summary_dir, filename), 'r', encoding='utf-8') as ref_file:\n            reference_summary = ref_file.read()\n            reference_summaries.append({'id': filename, 'summary': reference_summary})\n\n        # Tokenize and generate summary using Pegasus\n        inputs = tokenizer(test_document, return_tensors=\"pt\", max_length=1024, truncation=True)\n        input_ids = inputs[\"input_ids\"].to(device)  # Send input_ids tensor to the device\n        attention_mask = inputs[\"attention_mask\"].to(device)  # Send attention mask to the device\n\n        # Generate the summary\n        summary_ids = model.generate(input_ids, attention_mask=attention_mask, max_length=150, min_length=40, \n                                     length_penalty=2.0, num_beams=4, early_stopping=True)\n        generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n        generated_summaries.append({'id': filename, 'summary': generated_summary})\n\n        # Calculate cosine similarity using sentence embeddings\n        ref_embedding = sentence_model.encode([reference_summary])[0]\n        gen_embedding = sentence_model.encode([generated_summary])[0]\n\n        cosine_sim = cosine_similarity([ref_embedding], [gen_embedding])\n        cosine_similarities.append(cosine_sim[0][0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate average cosine similarity\naverage_cosine_similarity = np.mean(cosine_similarities)\nprint(f\"Average Cosine Similarity for Pegasus: {average_cosine_similarity}\")\n\n# Extract summaries text\nplain_generated_summaries = [item['summary'] for item in generated_summaries]\nplain_reference_summaries = [[item['summary']] for item in reference_summaries]\n\n# Calculate ROUGE score\nrouge_scores = rouge.compute(predictions=plain_generated_summaries, references=plain_reference_summaries)\nprint(f\"ROUGE scores for Pegasus: {rouge_scores}\")\n\n# Calculate BERTScore\nP, R, F1 = score(plain_generated_summaries, plain_reference_summaries, lang='en', rescale_with_baseline=True)\navg_f1 = np.mean(F1.numpy())\nprint(f\"BERTScore F1 for Pegasus: {avg_f1}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After obtaining the Rouge scores and bert score of the fine-tuned pegasus model, we can see that these scores are higher compared to the pre-trained model. Thus, training the model improved its performance.","metadata":{}},{"cell_type":"markdown","source":"# 4. Download generated summaries and reference summaries","metadata":{}},{"cell_type":"markdown","source":"Here, we downloaded summaries generated by fine-tuned pegasus model for further classification between pegasus generated summaries and GPT-4t generated summaries.","metadata":{}},{"cell_type":"code","source":"# Create the dataset\ndataset = []\nfor gen, ref in zip(generated_summaries, reference_summaries):\n    dataset.append({\n        'id': gen['id'],  # File name as id\n        'generated_summary': gen['summary'],  # Generated summary\n        'reference_summary': ref['summary'],  # Reference summary\n        'label': 'Pegasus'  # Add label column with \"Pegasus\"\n    })\n\n# Convert to a Pandas DataFrame\ndf = pd.DataFrame(dataset)\n\n# Save the dataset to a CSV file\ndf.to_csv(\"summary_dataset.csv\", index=False, encoding='utf-8')\n\n# Display the first few rows of the dataset\nprint(df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example legal document text\ndocument_text = \"\"\"This Non-Disclosure Agreement (NDA) is made and entered into on February 21, 2025, by and between Alpha Innovations, a corporation duly organized under the laws of Texas, and Beta Solutions, a limited liability company registered in New York. The parties agree to maintain the confidentiality of proprietary information exchanged during discussions related to potential business collaboration\"\"\"\n\n# Get the summary\nsummary = summarize_legal_document(document_text)\n\n# Print the summary\nprint(\"Generated Summary:\")\nprint(summary)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ngrok config add-authtoken 2tM3DYgLA5nFdgtHTAeERq6sLJC_2Vsp1uCzyVVJc7qQLSNid\n!pip install pyngrok\n!pip install cors\n!pip install flask-cors\nimport os\nfrom flask import Flask, request, jsonify\nfrom flask_cors import CORS\nfrom transformers import pipeline\nimport os\nimport torch\nfrom flask import Flask, request, jsonify\nfrom transformers import PegasusTokenizer, PegasusForConditionalGeneration\nfrom pyngrok import ngrok\n\n# Set device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Use the directory that contains the full fine-tuned model (including tokenizer files)\nmodel_path = \"/kaggle/working/fine_tuned_pegasus_model\"\nif os.path.exists(model_path):\n    model = PegasusForConditionalGeneration.from_pretrained(model_path).to(device)\n    tokenizer = PegasusTokenizer.from_pretrained(model_path)\nelse:\n    model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\").to(device)\n    tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n\n# Summarization function\ndef summarize_legal_document(document_text, max_length=150, min_length=40, num_beams=4):\n    inputs = tokenizer(document_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n    input_ids = inputs[\"input_ids\"].to(device)\n    attention_mask = inputs[\"attention_mask\"].to(device)\n    summary_ids = model.generate(\n        input_ids,\n        attention_mask=attention_mask,\n        max_length=max_length,\n        min_length=min_length,\n        length_penalty=2.0,\n        num_beams=num_beams,\n        early_stopping=True\n    )\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n# Initialize Flask app\napp = Flask(__name__)\nCORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n\n# Endpoint for summarizing plain text\n@app.route('/summarize_text', methods=['POST'])\ndef summarize_text_api():\n    data = request.get_json()\n    if not data or \"document_text\" not in data:\n        return jsonify({\"error\": \"Please provide document_text in JSON payload\"}), 400\n\n    document_text = data[\"document_text\"]\n    summary = summarize_legal_document(document_text)\n    return jsonify({\"summary\": summary})\n\nif __name__ == '__main__':\n    public_url = ngrok.connect(5000).public_url\n    print(\"Public URL:\", public_url)\n    app.run(host='0.0.0.0', port=5000)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def summarize_legal_document(document_text, max_length=150, min_length=40, num_beams=4):\n\n    # Tokenize the input document\n    inputs = tokenizer(document_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n    input_ids = inputs[\"input_ids\"].to(device)\n    attention_mask = inputs[\"attention_mask\"].to(device)\n\n    # Generate summary\n    summary_ids = model.generate(\n        input_ids, \n        attention_mask=attention_mask, \n        max_length=max_length, \n        min_length=min_length, \n        length_penalty=2.0, \n        num_beams=num_beams, \n        early_stopping=True\n    )\n\n    # Decode summary\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return summary\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-22T06:59:47.726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install pyngrok","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}